"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8864],{3905:function(e,n,t){t.d(n,{Zo:function(){return d},kt:function(){return c}});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),m=p(t),c=r,k=m["".concat(s,".").concat(c)]||m[c]||u[c]||i;return t?a.createElement(k,l(l({ref:n},d),{},{components:t})):a.createElement(k,l({ref:n},d))}));function c(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,l=new Array(i);l[0]=m;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var p=2;p<i;p++)l[p]=t[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},6178:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return o},contentTitle:function(){return s},metadata:function(){return p},toc:function(){return d},default:function(){return m}});var a=t(7462),r=t(3366),i=(t(7294),t(3905)),l=["components"],o={},s="Laboratorio 2: Resumen te\xf3rico",p={unversionedId:"labs/intro_teorica_2",id:"labs/intro_teorica_2",isDocsHomePage:!1,title:"Laboratorio 2: Resumen te\xf3rico",description:"Breve repaso de lexers. Estados especiales del DFA de un lexer. Explicaci\xf3n de",source:"@site/docs/labs/2_intro_teorica_2.md",sourceDirName:"labs",slug:"/labs/intro_teorica_2",permalink:"/docs/labs/intro_teorica_2",editUrl:"https://github.com/compiladores/compiladores.github.io/edit/master/docs/docs/labs/2_intro_teorica_2.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Laboratorio 1: Resumen te\xf3rico",permalink:"/docs/labs/intro_teorica"},next:{title:"Laboratorio 1: automatas",permalink:"/docs/labs/1"}},d=[{value:"Bibliograf\xeda",id:"bibliograf\xeda",children:[]},{value:"\xbfQu\xe9 es un lexer? (tiger 2.1)",id:"qu\xe9-es-un-lexer-tiger-21",children:[{value:"Ejemplo",id:"ejemplo",children:[]}]},{value:"\xbfC\xf3mo se describe un lexer? (tiger 2.2)",id:"c\xf3mo-se-describe-un-lexer-tiger-22",children:[{value:"Ejemplo",id:"ejemplo-1",children:[]}]},{value:"DFA derivado de un lexer",id:"dfa-derivado-de-un-lexer",children:[{value:"Ejemplo de deivaci\xf3n de un DFA para un lexer",id:"ejemplo-de-deivaci\xf3n-de-un-dfa-para-un-lexer",children:[]}]},{value:"flex",id:"flex",children:[]},{value:"Prioridad entre reglas",id:"prioridad-entre-reglas",children:[]}],u={toc:d};function m(e){var n=e.components,o=(0,r.Z)(e,l);return(0,i.kt)("wrapper",(0,a.Z)({},u,o,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"laboratorio-2-resumen-te\xf3rico"},"Laboratorio 2: Resumen te\xf3rico"),(0,i.kt)("p",null,"Breve repaso de lexers. Estados especiales del DFA de un lexer. Explicaci\xf3n de\nun ejemplo de lex/flex."),(0,i.kt)("h2",{id:"bibliograf\xeda"},"Bibliograf\xeda"),(0,i.kt)("p",null,"Tiger book: 2.1, 2.2, 2.3\n",(0,i.kt)("a",{parentName:"p",href:"https://westes.github.io/flex/manual/"},"Manual de flex"),"."),(0,i.kt)("h2",{id:"qu\xe9-es-un-lexer-tiger-21"},"\xbfQu\xe9 es un lexer? (tiger 2.1)"),(0,i.kt)("p",null,"Un lexer convierte una secuencia de caracteres en una secuencia de ",(0,i.kt)("strong",{parentName:"p"},"tokens"),"."),(0,i.kt)("h3",{id:"ejemplo"},"Ejemplo"),(0,i.kt)("p",null,"Fragmento de c\xf3digo:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-c"},'float matchO(char *s) { /* find a zero */\n    if (!strncmp(s, "0.0", 3))\n    return 0.;\n}\n')),(0,i.kt)("p",null,"Secuencia de tokens que podr\xeda extraer el lexer de C:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'    [\n        \n        (KEYWORD_FLOAT), (ID,"match0"), (LEFT_PAREN), (KEYWORD_CHAR), (STAR), (ID,"s"),(RIGHT_PAREN), (LEFT_BRACE),\n\n        (KEYWORD_IF),(LEFT_PAREN),(BANG),(ID,"strcmp"),(LEFT_PAREN),(ID,"s"),(COMMA),(STRING,"0.0"),(COMMA),(NUM,"3"),(RIGHT_PAREN),(RIGHT_PAREN),\n\n        (KEYWORD_RETURN),(REAL,"0."),(SEMICOLON),\n        \n        (RIGHT_BRACE),\n        \n        (EOF),\n    ]\n')),(0,i.kt)("p",null,"Notar que:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"El lexer hace desaparecer los comentarios"),(0,i.kt)("li",{parentName:"ul"},"El lexer hace desaparecer el espacio en blanco"),(0,i.kt)("li",{parentName:"ul"},"El lexer no interpreta ",(0,i.kt)("inlineCode",{parentName:"li"},"char*")," como un puntero a ",(0,i.kt)("inlineCode",{parentName:"li"},"char")," sino que unicamente\nreconoce ",(0,i.kt)("inlineCode",{parentName:"li"},"(KEYWORD_CHAR), (STAR)"),". El lexer no extrae informaci\xf3n sem\xe1ntica.")),(0,i.kt)("h2",{id:"c\xf3mo-se-describe-un-lexer-tiger-22"},"\xbfC\xf3mo se describe un lexer? (tiger 2.2)"),(0,i.kt)("p",null,"Para describir un lexer, lo \xfanico que necesitamos es un listado de expresiones\nregulares. Las expresiones regulares que est\xe1n m\xe1s arriba tienen mayor prioridad\nque las que est\xe1n m\xe1s abajo en la lista."),(0,i.kt)("h3",{id:"ejemplo-1"},"Ejemplo"),(0,i.kt)("p",null,"Algunas de las expresiones regulares que podr\xeda haber en el ejemplo anterior:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Expresi\xf3n regular"),(0,i.kt)("th",{parentName:"tr",align:null},"tipo de token"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"float")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"KEYWORD_FLOAT"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"(")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"LEFT_PAREN"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"[0-9]+")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"NUM"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"([0-9]+\\.[0-9]*)\\|([0-9]*\\.[0-9]+)")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"REAL"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"[a-z][a-zO-9]*")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"ID"))))),(0,i.kt)("p",null,"Notar que:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"float")," podr\xeda interpretarse como un ",(0,i.kt)("inlineCode",{parentName:"li"},"ID"),", pero se interpreta como\n",(0,i.kt)("inlineCode",{parentName:"li"},"KEYWORD_FLOAT"),", debido a su posici\xf3n en la lista"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"floated")," ser\xeda un ",(0,i.kt)("inlineCode",{parentName:"li"},"ID")," y no un ",(0,i.kt)("inlineCode",{parentName:"li"},"KEYWORD_FLOAT")," con un ",(0,i.kt)("inlineCode",{parentName:"li"},"ed")," colgando, debido a\nque el lexer busca la coincidencia m\xe1s larga (",(0,i.kt)("em",{parentName:"li"},"longest match"),"). ",(0,i.kt)("strong",{parentName:"li"},"Tener esto\nen cuenta es muy importante para resolver los lexers autom\xe1ticos, ya que\nlex/flex respeta el principio del ",(0,i.kt)("em",{parentName:"strong"},"longest match")))),(0,i.kt)("h2",{id:"dfa-derivado-de-un-lexer"},"DFA derivado de un lexer"),(0,i.kt)("p",null,'Por medio de algunos algoritmos relativamente simples que no se describen aqu\xed,\nes posible convertir cualquier expresi\xf3n regular en un DFA, y combinar estos DFA\npara crear otro DFA "especial". Este DFA "especial" cumple todas las\nformalidades matem\xe1ticas de un DFA pero se interpreta de una forma especial para\nextraer tokens. Para lenguajes simples es posible intuir el DFA final sin pasar\npor los pasos intermedios.'),(0,i.kt)("h3",{id:"ejemplo-de-deivaci\xf3n-de-un-dfa-para-un-lexer"},"Ejemplo de deivaci\xf3n de un DFA para un lexer"),(0,i.kt)("p",null,"Este lenguaje se llama ",(0,i.kt)("inlineCode",{parentName:"p"},"4++"),". Esta compuesto por 3 tipos de tokens, que pueden\nestar separados por guiones bajos."),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Expresi\xf3n regular"),(0,i.kt)("th",{parentName:"tr",align:null},"tipo de token"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"40")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"CUARENTA"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"4+")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"CUATROS"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"\\+\\+")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"MAS_MAS"))))),(0,i.kt)("p",null,"Ejemplos de frases v\xe1lidas |frase|tokens| |-|-|\n|",(0,i.kt)("inlineCode",{parentName:"p"},"4444++40"),"|",(0,i.kt)("inlineCode",{parentName:"p"},"(CUATROS,4444),(MAS_MAS,++),(CUARENTA,40)"),"|\n|",(0,i.kt)("inlineCode",{parentName:"p"},"++++4444"),"|",(0,i.kt)("inlineCode",{parentName:"p"},"(MAS_MAS,++),(MAS_MAS,++),(CUATROS,4444)"),"|\n|",(0,i.kt)("inlineCode",{parentName:"p"},"4__40"),"|",(0,i.kt)("inlineCode",{parentName:"p"},"(CUATROS,4),(CUARENTA,40)"),"| |",(0,i.kt)("inlineCode",{parentName:"p"},"404"),"|",(0,i.kt)("inlineCode",{parentName:"p"},"(CUARENTA,40),(CUATROS,4)"),"|"),(0,i.kt)("p",null,"Ejemplos de frases inv\xe1lidas |frase|problema| |-|-| |",(0,i.kt)("inlineCode",{parentName:"p"},"4+40"),"|el + debe estar\nseguido de otro +| |",(0,i.kt)("inlineCode",{parentName:"p"},"4 40"),"|el espacio es un caracter inv\xe1lido| |",(0,i.kt)("inlineCode",{parentName:"p"},"400"),"|se lexea\n",(0,i.kt)("inlineCode",{parentName:"p"},"40")," pero ningun token empieza con ",(0,i.kt)("inlineCode",{parentName:"p"},"0"),", el segundo ",(0,i.kt)("inlineCode",{parentName:"p"},"0")," no se puede consumir|\n|",(0,i.kt)("inlineCode",{parentName:"p"},"hola"),"|ning\xfan token empieza con ",(0,i.kt)("inlineCode",{parentName:"p"},"h"),"| |",(0,i.kt)("inlineCode",{parentName:"p"},"440"),"|se lexea ",(0,i.kt)("inlineCode",{parentName:"p"},"(CUATROS,44)")," y luego no\nhay c\xf3mo consumir el ",(0,i.kt)("inlineCode",{parentName:"p"},"0"),"|"),(0,i.kt)("p",null,"Aut\xf3mata de cada expresi\xf3n regular por separado:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"separados",src:t(7743).Z})),(0,i.kt)("p",null,"Los aut\xf3matas derivados de lexers tienen los siguientes estados especiales:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Estado inicial"),": siempre existe como un estado separado"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Estado tokenizable"),": en este estado los caracteres consumidos conforman el\ntoken. Son los estados de aceptaci\xf3n de los DFA de arriba"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Estado inv\xe1lido"),": Cuando el DFA llega a este estado, el lexer lanza una\nexcepci\xf3n"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Estado muerto"),": Explicado a continuaci\xf3n")),(0,i.kt)("p",null,"Aut\xf3matas unidos sin estado muerto:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"unidos 1",src:t(2515).Z})),(0,i.kt)("p",null,"Este aut\xf3mata no sirve para un lexer. Analicemos 2 algoritmos distintos de lexer\npara convencernos de esto."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Optimista: cuando llega a un estado de aceptaci\xf3n, se detiene y emite un\ntoken. Esta implementaci\xf3n no es buena porque para el string ",(0,i.kt)("inlineCode",{parentName:"li"},"444")," emite\n",(0,i.kt)("inlineCode",{parentName:"li"},"(CUATROS,4),(CUATROS,4),(CUATROS,4)")),(0,i.kt)("li",{parentName:"ul"},"Pesimista: Cuando llega al estado de aceptaci\xf3n intenta continuar y emite el\ntoken anterior al llegar al estado inv\xe1lido. Funciona bien para ",(0,i.kt)("inlineCode",{parentName:"li"},"444")," pero no\npara ",(0,i.kt)("inlineCode",{parentName:"li"},"44_40")," porque, al consumir el caracter ",(0,i.kt)("inlineCode",{parentName:"li"},"_"),", llega al estado inv\xe1lido al\nigual que lo har\xeda si consumiera una ",(0,i.kt)("inlineCode",{parentName:"li"},"h"),". No permite diagnosticar errores\ncorrectamente.")),(0,i.kt)("p",null,"La soluci\xf3n es incluir estados ",(0,i.kt)("em",{parentName:"p"},"muerto"),". Los estados de tokens v\xe1lidos no ser\xe1n\nestados de aceptaci\xf3n sino que lo ser\xe1 este \xfaltimo. El estado muerto se\xf1ala de\nforma un\xedvoca."),(0,i.kt)("p",null,"Antes, introducimos una nueva notaci\xf3n para el estado inv\xe1lido:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"unidos 2",src:t(3247).Z})),(0,i.kt)("p",null,"Aut\xf3matas unidos con estado muerto (los estados tokenizables se resaltan pero\n",(0,i.kt)("strong",{parentName:"p"},"no son especiales matematicamente"),"):"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"unidos 3",src:t(7724).Z})),(0,i.kt)("p",null,"Breve descripci\xf3n del algoritmo que observa el aut\xf3mata:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Iniciar constantemente recorridos del aut\xf3mata."),(0,i.kt)("li",{parentName:"ul"},"Cada recorrido del aut\xf3mata consume caracteres hasta alcanzar un estado\ninv\xe1lido o un estado muerto.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"En el primer caso (estado inv\xe1lido) emitir un error."),(0,i.kt)("li",{parentName:"ul"},"En el segundo caso (estado muerto), emitir el token correspondiente al\nestado tokenizable anterior, si es posible."))),(0,i.kt)("li",{parentName:"ul"},"Reaprovechar el caracter utilizado para la \xfaltima transici\xf3n en el siguiente\nrecorrido del aut\xf3mata")),(0,i.kt)("h2",{id:"flex"},"flex"),(0,i.kt)("p",null,"Flex es un generador de lexers. Utiliza un formato de archivo especial para\ngenerar un lexer escrito en ",(0,i.kt)("inlineCode",{parentName:"p"},"C"),". Formato de un archivo flex:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"definitions\n%%\nrules\n%%\nuser code\n")),(0,i.kt)("p",null,"En el laboratorio 2 se usa \xfanicamente la secci\xf3n ",(0,i.kt)("inlineCode",{parentName:"p"},"rules"),". La secci\xf3n ",(0,i.kt)("inlineCode",{parentName:"p"},"rules")," es\nuna secuencia de expresiones regulares seguidas de algo de c\xf3digo C (siempre\nllamadas a ",(0,i.kt)("inlineCode",{parentName:"p"},"printf")," en el laboratorio 2). C\xf3digo para el lenguaje cuyo aut\xf3mata\nse estudi\xf3 previamente:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'%%\n40      { printf("CUARENTA %s\\n",yytext); }\n4+      { printf("CUATROS %s\\n",yytext); }\n\\+\\+      { printf("MAS_MAS %s\\n",yytext); }\n_       { }\n.     { printf("ERROR"); exit(1); }\n%%\n')),(0,i.kt)("p",null,"Instrucciones para correr el archivo:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"instalar ",(0,i.kt)("inlineCode",{parentName:"li"},"flex")," y ",(0,i.kt)("inlineCode",{parentName:"li"},"gcc")," con ",(0,i.kt)("inlineCode",{parentName:"li"},"apt")),(0,i.kt)("li",{parentName:"ol"},"Escribir el c\xf3digo de arriba en un archivo ",(0,i.kt)("inlineCode",{parentName:"li"},"ejemplo.lex")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"flex -i -I ejemplo.lex")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"gcc -g lex.yy.c -o ejemplo -ll")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"./ejemplo")," consume texto por stdin y ejecuta lo correspondiente")),(0,i.kt)("h2",{id:"prioridad-entre-reglas"},"Prioridad entre reglas"),(0,i.kt)("p",null,"Se introduce un nuevo token ",(0,i.kt)("inlineCode",{parentName:"p"},"4[0-9]"),". Esta regla se escribe arriba de todo,\nenconces no se detecta el token ",(0,i.kt)("inlineCode",{parentName:"p"},"CUARENTA")," ni la instancia ",(0,i.kt)("inlineCode",{parentName:"p"},"44")," de ",(0,i.kt)("inlineCode",{parentName:"p"},"CUATROS"),".\n",(0,i.kt)("strong",{parentName:"p"},"Variando la posici\xf3n de la nueva regla se cambia la prioridad de la misma para\ntokens del mismo largo"),". N\xf3tese que a\xfan se detecta ",(0,i.kt)("inlineCode",{parentName:"p"},"444")," (con ",(0,i.kt)("inlineCode",{parentName:"p"},"4[0-9]")," arriba\nde todo) como una instancia de ",(0,i.kt)("inlineCode",{parentName:"p"},"CUATROS"),", debido a la prioridad del ",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("em",{parentName:"strong"},"longest\nmatch"))," por sobre la posici\xf3n de la regla."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'%%\n4[0-9]      { printf("CUARENTA_Y_PICO %s\\n",yytext); }\n40      { printf("CUARENTA %s\\n",yytext); }\n4+      { printf("CUATROS %s\\n",yytext); }\n\\+\\+      { printf("MAS_MAS %s\\n",yytext); }\n_       { }\n.     { printf("ERROR"); exit(1); }\n%%\n')))}m.isMDXComponent=!0},7743:function(e,n,t){n.Z=t.p+"assets/images/separados.drawio-cc071dfc38628459bd63ef24663f2614.png"},7724:function(e,n,t){n.Z=t.p+"assets/images/unidos_con_dead.drawio-eaa0788682a224ac0283bb3ddeef53e6.png"},2515:function(e,n,t){n.Z=t.p+"assets/images/unidos_sin_dead.drawio-e654e72ca0f6ca156a93b1cf561b72aa.png"},3247:function(e,n,t){n.Z=t.p+"assets/images/unidos_sin_dead_mini_invalido.drawio-fa828b2aba6f58ee55b0d52e7075a83c.png"}}]);